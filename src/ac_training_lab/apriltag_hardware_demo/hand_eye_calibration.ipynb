{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af474d56",
   "metadata": {},
   "source": [
    "# Hand-Eye Calibration\n",
    "\n",
    "This notebook provides hand-eye calibration for the AprilTag minimal working example. It is intended for development use only. The resulting hand-eye transformation matrix (`hand_eye_calibration.npy`) will be hard-coded into the main notebook (src\\ac_training_lab\\apriltag_hardware_demo\\apriltag_hardware_demo.ipynb) for system operation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbccc85",
   "metadata": {},
   "source": [
    "## Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f54a179",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install numpy scipy opencv-python pillow matplotlib gradio-client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e7d0fc",
   "metadata": {},
   "source": [
    "## Connecting to the Cobot\n",
    "\n",
    "We first define some helper functions to display result and images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac82cc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import json\n",
    "\n",
    "def display_image(image_path):\n",
    "\ttry:\n",
    "\t\timg = Image.open(image_path).convert(\"RGB\")\n",
    "\t\tplt.imshow(img)\n",
    "\t\tplt.title(\"Cobot view\")\n",
    "\t\tplt.show()\n",
    "\texcept Exception as e:\n",
    "\t\tprint(f\"An error occurred: {e}\")\n",
    "\n",
    "def display_result(result):\n",
    "\tqueue_status_str = result[-1].replace('\\n', ' ')\n",
    "\tprint(f\"queue status: {queue_status_str}\")\n",
    "\tprint(f\"response json: {None if result[0] is None else json.loads(result[0])}\")\n",
    "\tif len(result) == 3:\n",
    "\t\tif result[1] is None:\n",
    "\t\t\treturn\n",
    "\t\tdisplay_image(result[1]['value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c73d27",
   "metadata": {},
   "source": [
    "Connect to the cobot to begin data collection and calibration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f42506",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gradio_client import Client\n",
    "import uuid\n",
    "import getpass  \n",
    "\n",
    "USER_ID = str(uuid.uuid4())\n",
    "print(f\"Your user id: {USER_ID}\")\n",
    "\n",
    "hf_token = getpass.getpass(\"Enter your Hugging Face Token:\")\n",
    "\n",
    "client = Client(\n",
    "    \"AccelerationConsortium/cobot280pi-gradio-g9sv\",\n",
    "    hf_token=hf_token\n",
    ")\n",
    "\n",
    "client.view_api()\n",
    "\n",
    "result = client.predict(\n",
    "    user_id=USER_ID,\n",
    "    api_name=\"/enter_queue\"\n",
    ")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82de583",
   "metadata": {},
   "source": [
    "## Data Collection Instructions\n",
    "\n",
    "\n",
    "Prepare a checkerboard pattern and attach it to a wall or stable surface.\n",
    "\n",
    "In this section, run the code cells approximately 20 times.  \n",
    "For each sample:\n",
    "\n",
    "1. Adjust the cobot using first two cells so that the entire checkerboard is clearly visible in the image.\n",
    "2. Run the third cell to save the image and corresponding cobot pose into a JSON file for hand-eye calibration.\n",
    "\n",
    "Try to capture images from diverse positions and angles to improve calibration accuracy.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5428e353",
   "metadata": {},
   "source": [
    "### 1. Cell to Adjust Cobot Angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0809a06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell to adjust by angle\n",
    "result = client.predict(\n",
    "\tuser_id=USER_ID,\n",
    "\tangle0 = 0,\n",
    "\tangle1 = 20,\n",
    "\tangle2 = 0,\n",
    "\tangle3 = 0,\n",
    "\tangle4 = 0,\n",
    "\tangle5 = 0,\n",
    "\tmovement_speed =50,\n",
    "\tapi_name=\"/control_angles\"\n",
    ")\n",
    "display_result(result)\n",
    "\n",
    "result = client.predict(\n",
    "\tuser_id=USER_ID,\n",
    "\tapi_name=\"/query_camera\"\n",
    ")\n",
    "print(result)\n",
    "display_result(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99875177",
   "metadata": {},
   "source": [
    "### 2. Cell to Adjust Cobot Coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b8a8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell to adjust by angle\n",
    "result = client.predict(\n",
    "    user_id=USER_ID,\n",
    "    x = 10.0,  \n",
    "    y = 0,\n",
    "    z = 0,\n",
    "    roll = 0,\n",
    "    pitch = 0,\n",
    "    yaw = 0,\n",
    "    movement_speed = 50,\n",
    "    api_name=\"/control_coords\"\n",
    ")\n",
    "\n",
    "display_result(result)\n",
    "\n",
    "result = client.predict(\n",
    "\tuser_id=USER_ID,\n",
    "\tapi_name=\"/query_camera\"\n",
    ")\n",
    "print(result)\n",
    "display_result(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4c9f94",
   "metadata": {},
   "source": [
    "### 3. Save Data into JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef8c829",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "import cv2\n",
    "\n",
    "current_dir = os.path.dirname(__file__)\n",
    "data_dir = os.path.join(current_dir, \"apriltag_hardware_demo\")\n",
    "json_path = os.path.join(data_dir, \"hand_eye_calibration_data.json\")\n",
    "\n",
    "if not os.path.exists(json_path):\n",
    "    data_json = {\"records\": []}\n",
    "else:\n",
    "    with open(json_path, 'r') as f:\n",
    "        data_json = json.load(f)\n",
    "\n",
    "result_img = client.predict(\n",
    "    user_id=USER_ID,\n",
    "    api_name=\"/query_camera\"\n",
    ")\n",
    "print(result_img)\n",
    "display_result(result_img)\n",
    "\n",
    "pil_image = result_img[\"image\"]\n",
    "\n",
    "image_array = np.array(pil_image)\n",
    "\n",
    "if image_array.shape[-1] == 3:\n",
    "    image_array = cv2.cvtColor(image_array, cv2.COLOR_RGB2BGR)\n",
    "image_id = len(data_json[\"records\"]) + 1\n",
    "image_filename = f\"{image_id}.jpg\"\n",
    "image_path = os.path.join(data_dir, image_filename)\n",
    "cv2.imwrite(image_path, image_array)\n",
    "print(f\"Saved image to {image_path}\")\n",
    "\n",
    "result_pose = client.predict(\n",
    "    user_id=USER_ID,\n",
    "    api_name=\"/query_coords\"\n",
    ")\n",
    "print(result_pose)\n",
    "display_result(result_pose)\n",
    "\n",
    "query_coords = result_pose  \n",
    "\n",
    "x, y, z = [coord / 1000 for coord in query_coords[:3]]\n",
    "rx_deg, ry_deg, rz_deg = query_coords[3:]\n",
    "rx, ry, rz = np.radians([rx_deg, ry_deg, rz_deg])\n",
    "\n",
    "rotation = R.from_euler('xyz', [rx, ry, rz]).as_matrix()\n",
    "\n",
    "pose_matrix = np.eye(4)\n",
    "pose_matrix[:3, :3] = rotation\n",
    "pose_matrix[:3, 3] = [x, y, z]\n",
    "\n",
    "record = {\n",
    "    \"image_path\": image_filename,\n",
    "    \"pose_matrix\": pose_matrix.tolist()  \n",
    "}\n",
    "data_json[\"records\"].append(record)\n",
    "\n",
    "with open(json_path, 'w') as f:\n",
    "    json.dump(data_json, f, indent=2)\n",
    "print(f\"Record added to {json_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a801d172",
   "metadata": {},
   "source": [
    "## Main function for hand-eye calibration\n",
    "Next, we define helper functions for calibration, and specify the checkerboard parameters:  \n",
    "- `XX`: number of inner corners along the width  \n",
    "- `YY`: number of inner corners along the height  \n",
    "- `L`: size of each square (in meters)\n",
    "\n",
    "The function will perform both camera calibration and hand-eye calibration, and save the camera intrinsics into `camera_params.npy` for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf0928b",
   "metadata": {},
   "outputs": [],
   "source": [
    "XX = 9  \n",
    "YY = 12\n",
    "L = 0.025  # need to check this !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b978eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import cv2\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "\n",
    "current_dir = os.path.dirname(__file__)  \n",
    "data_dir = os.path.join(current_dir, \"apriltag_hardware_demo\")\n",
    "\n",
    "json_path = os.path.join(data_dir, \"hand_eye_calibration_data.json\")\n",
    "camera_params_path = os.path.join(data_dir, \"camera_params.npy\")\n",
    "\n",
    "def func():\n",
    "    with open(json_path, 'r') as f:\n",
    "        data_json = json.load(f)\n",
    "\n",
    "    objp = np.zeros((XX * YY, 3), np.float32)\n",
    "    objp[:, :2] = np.mgrid[0:XX, 0:YY].T.reshape(-1, 2)\n",
    "    objp *= L\n",
    "\n",
    "    obj_points = []  \n",
    "    img_points = [] \n",
    "\n",
    "    R_tool = []\n",
    "    t_tool = []\n",
    "\n",
    "    criteria = (cv2.TERM_CRITERIA_MAX_ITER | cv2.TERM_CRITERIA_EPS, 30, 0.001)\n",
    "\n",
    "    for record in data_json[\"records\"]:\n",
    "        image_path = os.path.join(data_dir, record[\"image_path\"])\n",
    "\n",
    "        if not os.path.exists(image_path):\n",
    "            print(f\"Image {image_path} not found. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        img = cv2.imread(image_path)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        size = gray.shape[::-1]\n",
    "\n",
    "        ret, corners = cv2.findChessboardCorners(gray, (XX, YY), None)\n",
    "\n",
    "        if ret:\n",
    "            obj_points.append(objp)\n",
    "            corners2 = cv2.cornerSubPix(gray, corners, (5, 5), (-1, -1), criteria)\n",
    "            img_points.append(corners2)\n",
    "\n",
    "            pose_matrix = np.array(record[\"pose_matrix\"])\n",
    "            R_tool.append(pose_matrix[:3, :3])\n",
    "            t_tool.append(pose_matrix[:3, 3])\n",
    "        else:\n",
    "            print(f\"Chessboard not detected in {image_path}\")\n",
    "\n",
    "    ret, K, dist, rvecs, tvecs = cv2.calibrateCamera(\n",
    "        obj_points,\n",
    "        img_points,\n",
    "        size,\n",
    "        cameraMatrix=None,\n",
    "        distCoeffs=None\n",
    "    )\n",
    "\n",
    "    camera_params = {\n",
    "        \"camera_matrix\": K,\n",
    "        \"dist_coeff\": dist\n",
    "    }\n",
    "    np.save(camera_params_path, camera_params)\n",
    "    print(f\"Saved camera parameters to {camera_params_path}\")\n",
    "\n",
    "    R_ce, t_ce = cv2.calibrateHandEye(R_tool, t_tool, rvecs, tvecs, cv2.CALIB_HAND_EYE_TSAI)\n",
    "\n",
    "    return R_ce, t_ce\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc4221f",
   "metadata": {},
   "source": [
    "Finally, run `func()` to compute the hand-eye calibration and save the resulting matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57e6559",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "R_ce, t_ce = func()\n",
    "\n",
    "hand_eye_params = {\n",
    "    \"rotation_matrix\": R_ce,\n",
    "    \"translation_vector\": t_ce\n",
    "}\n",
    "\n",
    "hand_eye_path = os.path.join(data_dir, \"hand_eye_calibration.npy\")\n",
    "np.save(hand_eye_path, hand_eye_params)\n",
    "print(f\"Saved hand-eye calibration to {hand_eye_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7156af01",
   "metadata": {},
   "source": [
    "## JSON Data Management"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7839022c",
   "metadata": {},
   "source": [
    "### Clear JSON File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd4d52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# Define paths\n",
    "current_dir = os.path.dirname(__file__)\n",
    "data_dir = os.path.join(current_dir, \"apriltag_hardware_demo\")\n",
    "json_path = os.path.join(data_dir, \"hand_eye_calibration_data.json\")\n",
    "\n",
    "# Create new empty json structure\n",
    "data_json = {\"records\": []}\n",
    "\n",
    "# Save empty file\n",
    "with open(json_path, 'w') as f:\n",
    "    json.dump(data_json, f, indent=2)\n",
    "\n",
    "print(f\"JSON file at {json_path} has been cleared.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0237b6",
   "metadata": {},
   "source": [
    "### Delete Previous Record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6aba36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# Load json\n",
    "with open(json_path, 'r') as f:\n",
    "    data_json = json.load(f)\n",
    "\n",
    "if len(data_json[\"records\"]) > 0:\n",
    "    data_json[\"records\"].pop()\n",
    "    with open(json_path, 'w') as f:\n",
    "        json.dump(data_json, f, indent=2)\n",
    "    print(\"Last record has been removed.\")\n",
    "else:\n",
    "    print(\"No records to remove.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
